{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_pracs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ZKjVN0J9nf"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfUAUP-mK1CR"
      },
      "source": [
        "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\r\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWC7wP2qMdK4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47085de2-2d1b-4d8a-c1ef-2cce8f4c4273"
      },
      "source": [
        "word_tokens = word_tokenize(example_sent)\r\n",
        "word_tokens"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'sample',\n",
              " 'sentence',\n",
              " ',',\n",
              " 'showing',\n",
              " 'off',\n",
              " 'the',\n",
              " 'stop',\n",
              " 'words',\n",
              " 'filtration',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paRTsQqmMm-b",
        "outputId": "60063446-31b5-4255-9f9b-0b0f3647a153"
      },
      "source": [
        "filtered_sentence = [w for w in word_tokens if not w in stop_words]\r\n",
        "print(\" \".join(filtered_sentence))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This sample sentence , showing stop words filtration .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u08h_nBM5Tj"
      },
      "source": [
        "from nltk.util import ngrams, bigrams, trigrams"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J05pWw_9M51a"
      },
      "source": [
        "sen = \"Dummy sentence to demonstrate bigrams\"\r\n",
        "nltk_tokens = word_tokenize(sen) #using tokenize from NLKT and not split() because split() does not take into account punctuation"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxGGVWLIeONB",
        "outputId": "478fffbb-d108-4513-b820-4a071c0c41d4"
      },
      "source": [
        "#splitting sentence into bigrams and trigrams\r\n",
        "print(list(bigrams(nltk_tokens)))\r\n",
        "print(list(trigrams(nltk_tokens)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Dummy', 'sentence'), ('sentence', 'to'), ('to', 'demonstrate'), ('demonstrate', 'bigrams')]\n",
            "[('Dummy', 'sentence', 'to'), ('sentence', 'to', 'demonstrate'), ('to', 'demonstrate', 'bigrams')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElhhJ53OeUA3"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "#letters only\r\n",
        "raw_text = \"this is a test. To demonstrate 2 regex expressions!!\"\r\n",
        "letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\r\n",
        "\r\n",
        "#keep numbers\r\n",
        "letnum_text = re.sub(\"[^a-zA-Z0-9\\s]+\", \" \",raw_text )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9DQj21-ev8o",
        "outputId": "6b978150-c867-4007-8393-5b49e424ab24"
      },
      "source": [
        "print(letnum_text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is a test  To demonstrate 2 regex expressions \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9rS46Qgz8n_"
      },
      "source": [
        "from collections import Counter \r\n",
        "def count_words_fast(text):      \r\n",
        "    text = text.lower()  \r\n",
        "    skips = [\".\", \", \", \":\", \";\", \"'\", '\"']  \r\n",
        "    for ch in skips:  \r\n",
        "        text = text.replace(ch, \"\")  \r\n",
        "    word_counts = Counter(text.split(\" \"))  \r\n",
        "    return word_counts  \r\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO64td910F6g",
        "outputId": "089ee99c-895f-4b89-ab9c-af7bdeef752e"
      },
      "source": [
        "text = \"This is my test text. We're keeping this text short to keep things manageable and to keep things manageable.\"\r\n",
        "count_words_fast(text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'and': 1,\n",
              "         'is': 1,\n",
              "         'keep': 2,\n",
              "         'keeping': 1,\n",
              "         'manageable': 2,\n",
              "         'my': 1,\n",
              "         'short': 1,\n",
              "         'test': 1,\n",
              "         'text': 2,\n",
              "         'things': 2,\n",
              "         'this': 2,\n",
              "         'to': 2,\n",
              "         'were': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}